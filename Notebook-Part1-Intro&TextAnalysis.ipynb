{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEIF 102A\n",
    "---\n",
    "<img src=\"http://www.cleargoals.com/wp-content/uploads/2017/04/data-science-methods-and-algorithms-for-big-data.jpg\" style=\"width: 500px; height: 275px;\" />\n",
    "\n",
    "### Professor Veldhuis\n",
    "\n",
    "Sumerian Text Analysis\n",
    "\n",
    "*Estimated Time: X minutes*\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- Short sentence topic 1\n",
    "- Short sentence topic 2\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "1 - [Section 1: Intro to Python & Jupyter Notebooks](#section 1)<br>\n",
    "\n",
    "2 - [Section 2: Data Read & Prep](#section 2)<br>\n",
    "\n",
    "\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datascience in /Users/stephkim/anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: setuptools in /Users/stephkim/anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from datascience)\n",
      "Requirement already satisfied: coverage==3.7.1 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: coveralls==0.5 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: sphinx in /Users/stephkim/anaconda/lib/python3.6/site-packages/Sphinx-1.5.1-py3.6.egg (from datascience)\n",
      "Requirement already satisfied: folium==0.1.5 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: pytest in /Users/stephkim/anaconda/lib/python3.6/site-packages (from datascience)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from coveralls==0.5->datascience)\n",
      "Requirement already satisfied: requests>=1.0.0 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from coveralls==0.5->datascience)\n",
      "Requirement already satisfied: docopt>=0.6.1 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from coveralls==0.5->datascience)\n",
      "Requirement already satisfied: six>=1.5 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: Pygments>=2.0 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: docutils>=0.11 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: imagesize in /Users/stephkim/anaconda/lib/python3.6/site-packages (from sphinx->datascience)\n",
      "Requirement already satisfied: py>=1.4.29 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from pytest->datascience)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/stephkim/anaconda/lib/python3.6/site-packages (from Jinja2>=2.3->sphinx->datascience)\n",
      "Requirement already satisfied: pytz>=0a in /Users/stephkim/anaconda/lib/python3.6/site-packages (from babel!=2.0,>=1.3->sphinx->datascience)\n"
     ]
    }
   ],
   "source": [
    "! pip install datascience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Intro to Python  <a id='section 1'></a>\n",
    "- Learn how to work with Jupyter notebooks.\n",
    "- Learn about variables in Python, including variable types, variable assignment, and arithmetic.\n",
    "- Learn about functions in Python, including defining and calling functions, as well as scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Try running the code below. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# CODE\n",
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, let's try editing the code. In the cell below, replace \"friend\" with your name for a more personalized message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Jupyter notebooks, friend.\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to Jupyter notebooks, friend.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Programming in Python\n",
    "---\n",
    "Now that you are comfortable with using Jupyter notebooks, we can learn more about programming in this notebook.\n",
    "\n",
    "### What is Programming?\n",
    "**Programming** is giving the computer a set of step-by-step instructions to follow in order to execute a task. It's a lot like writing your own recipe book! For example, let's say you wanted to teach someone how to make a PB&J sandwich:\n",
    "1. Gather bread, peanut butter, jelly, and a spreading knife.\n",
    "2. Take out two slices of bread.\n",
    "3. Use the knife to spread peanut butter on one slice of bread.\n",
    "4. Use the knife to spread jelly on the other slice of bread.\n",
    "5. Put the two slices of bread together to make a sandwich.\n",
    "\n",
    "Just like that, programming is breaking up a complex task into smaller commands for the computer to understand and execute.\n",
    "\n",
    "In order to communicate with computers, however, we must talk to them in a way that they can understand us: via a **programming language**. \n",
    "\n",
    "There are many different kinds of programming languages, but we will be using **Python** because it is concise, simple to read, and applicable in a variety of projects - from web development to mobile apps to data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In programming, we often compute many values that we want to save so that we can use the result in a later step. For example, let's say that we want to find the number of words in a group of texts. Each text in the group has 100 words, and there are 20 texts. We can easily calculate this with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<p style=\"text-align: center\">$100 * 20 = 2000$ words</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "However, let's say that your friend Alexander asked you how many words there are in three groups (same conditions as the group explained above). We could, of course, perform the calculation in a similar manner:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<p style=\"text-align: center\">$(100 * 20) * 3 = 6000$ words</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But we see that we repeated the calculation in parentheses above. Instead of doing this calculation again, we could have saved the result from our first step (calculating the number of words in a group of 20 texts) as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is Python code that assigns variables.\n",
    "# The name to the left of the equals sign is the variable name.\n",
    "# The value to the right of the equals sign is the value of the variable.\n",
    "# Press Shift-Enter to run the code and see the value of our variable!\n",
    "\n",
    "words_in_group = 20 * 100 # This is equal to 2000.\n",
    "words_in_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then, we can simply multiply this variable by three to get the number of words in *three* groups of texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The code below takes the number of seconds in a day (which we calculated in the previous code cell)\n",
    "# and multiplies it by 3 to find the number of seconds in 3 days.\n",
    "\n",
    "words_in_three_group = words_in_group * 3  # This is equal to 259200.\n",
    "words_in_three_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As you can see, variables can be used to simplify calculations, make code more readable, and allow for repetition and reusability of code. \n",
    "\n",
    "### Variable Types\n",
    "\n",
    "Next, we'll talk about a few types of variables that you'll be using. As we saw in the example above, one common type of variable is the *integer* (positive and negative whole numbers). You'll also be using decimal numbers in Python, which are called *doubles* (positive and negative decimal numbers). \n",
    "\n",
    "A third type of variable used frequently in Python is the *string*; strings are essentially sequences of characters, and you can think of them as words or sentences. We denote strings by surrounding the desired value with quotes. For example, \"Data Science\" and \"2017\" are strings, while `bears` and `2020` (both without quotes) are not strings.\n",
    "\n",
    "Finally, the last variable type we'll go over is the *boolean*. They can take on one of two values: `True` or `False`. Booleans are often used to check conditions; for example, we might have a list of dogs, and we want to sort them into small dogs and large dogs. One way we could accomplish this is to say either `True` or `False` for each dog after seeing if the dog weighs more than 15 pounds. \n",
    "\n",
    "Here is a table that summarizes the information in this section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "|Variable Type|Definition|Examples|\n",
    "|-|-|-|\n",
    "|Integer|Positive and negative whole numbers|`42`, `-10`, `0`|\n",
    "|Double|Positive and negative decimal numbers|`73.9`, `2.4`, `0.0`|\n",
    "|String|Sequence of characters|`\"Go Bears!\"`, `\"variables\"`|\n",
    "|Boolean|True or false value|`True`, `False`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Arithmetic\n",
    "Now that we've discussed what types of variables we can use, let's talk about how we can combine them together. As we saw at the beginning of this section, we can do basic math in Python. Here is a table that shows how to write such operations:\n",
    "\n",
    "|Operation|Operator|Example|Value|\n",
    "|-|-|-|\n",
    "|Addition|+|`2 + 3`|`5`|\n",
    "|Subtraction|-|`2 - 3`|`-1`|\n",
    "|Multiplication|*|`2 * 3`|`6`|\n",
    "|Division|/|`7 / 3`|`2.66667`|\n",
    "|Remainder|%|`7 % 3`|`1`|\n",
    "|Exponentiation|**|`2 ** 0.5`|`1.41421`|\n",
    "\n",
    "In addition, you can use parentheses to denote priority, just like in math.\n",
    "\n",
    "As an exercise, try to predict what each of these lines below will print out. Then, run the cell and check your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "5.0\n",
      "60\n",
      "0\n",
      "2017.0\n"
     ]
    }
   ],
   "source": [
    "q_1 = (3 + 4) / 2\n",
    "print(q_1) # What prints here?\n",
    "\n",
    "q_2 = 3 + 4 / 2\n",
    "print(q_2) # What prints here?\n",
    "\n",
    "some_variable = 1 + 2 + 3 + 4 + 5\n",
    "q_3 = some_variable * 4\n",
    "print(q_3) # What prints here?\n",
    "\n",
    "q_4 = some_variable % 3\n",
    "print(q_4) # What prints here?\n",
    "\n",
    "step_1 = 6 * 5 - (6 * 3)\n",
    "step_2 = (2 ** 3) / 4 * 7\n",
    "q_5 = 1 + step_1 ** 2 * step_2\n",
    "print(q_5) # What prints here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can do many things with strings. Today you'll learn how to concatenate and find the length of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Concatenation is basically addition but with strings. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University of California, Berkeley\n",
      "UC Berkeley Near Eastern Studies 2018\n"
     ]
    }
   ],
   "source": [
    "print(\"University \" + \"of California, \" + \"Berkeley\") \n",
    "\n",
    "school = \"UC Berkeley \"\n",
    "department = \"Near Eastern Studies \"\n",
    "year = \"2018\"\n",
    "print(school + department + year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So far, you've learnt how to carry out basic operations on your inputs and assign variables to certain values.\n",
    "Now, let's try to be more efficient. \n",
    "\n",
    "Let's say we want to perform a certain operation on many different inputs that will produce distinct outputs. What do we do? We write a _**function**_.\n",
    "\n",
    "A function is a block of code which works a lot like a machine: it takes an input, does something to it, and produces an output. \n",
    "\n",
    "The input is put between brackets and can also be called the _argument_ or _parameter_. Functions can have multiple arguments.\n",
    "\n",
    "Try running the cell below after changing the variable _name_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello John Doe!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit this cell to your own name!\n",
    "name = \"John Doe\"\n",
    "\n",
    "# Our function\n",
    "def hello(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "hello(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Interesting, right? Now, you don't need to write 10 different lines with 10 different names to print a special greeting for each person. All you need to is write one function that does all the work for you!\n",
    "\n",
    "Functions are very useful in programming because they help you write shorter and more modular code. A good example to think of is the _print_ function, which we've used quite a lot in this module. It takes many different inputs and performs the specified task, printing its input, in a simple manner.\n",
    "\n",
    "Now, let's write our own function. Let's look at the following rules: \n",
    "\n",
    "### Defining\n",
    "- All functions must start with the \"def\" keyword.  \n",
    "- All functions must have a name, followed by parentheses, followed by a colon. Eg. def hello( ):\n",
    "- The brackets may have a variable that stores its arguments (inputs)\n",
    "- All functions must have a \"return\" statement which will return the output. Think of a function like a machine. When you put something inside, you want it to return something. Hence, this is very important.\n",
    "\n",
    "### Calling\n",
    "After you define a function, it's time to use it. This is known as _calling_ a function. \n",
    "\n",
    "To call a function, simply write the name of the function with your input variable in parantheses (argument).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-0919a320d65c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-0919a320d65c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def #name(argument):\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Complete this function\n",
    "def #name(argument):\n",
    "    return # function must return a value\n",
    "\n",
    "# Calling our function below...\n",
    "my_first_function(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scope\n",
    "---\n",
    "Programming is great, but it can also be quite peculiar sometimes. For example, each variable defined outside of any functions by default, is **global**. \n",
    "\n",
    "Try executing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ninurta, Son of Enlil!'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global Variable - name\n",
    "# Ninurta is from \"Ninurta's return to Nibru: a šir-gida to Ninurta\"\n",
    "description = \"Son of Enlil!\"\n",
    "\n",
    "# our function\n",
    "def title(description):\n",
    "    return \"Ninurta, \" + description\n",
    "\n",
    "# calling our function\n",
    "title(description)\n",
    "\n",
    "# un-comment the line below\n",
    "#title(\"Warrior of Enlil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Even though your argument was called _decription_, it didnt output \"Son of Enlil\", which was the **global** value of the variable called _decription_. Instead, it gave preference to the **local** value which was given to the function as an argument, \"Warrior of Enlil.\" \n",
    "\n",
    "Think of it as filling your coffeemaker (function) up with coffee (variable). If you have a variable with **global** access called _decription_ which is filled with coffee called \"Son of Enlil\", you can choose to either:\n",
    "\n",
    "1) Not input another value in your function. (Use the same name of the **global** variable as your argument)\n",
    "\n",
    "In this case, the **global** type of coffee will still be used. \n",
    "\n",
    "2) Choose to fill another value. In this case, your function will assign the value you pass as the argument to the “variable” which **is** the argument.\n",
    "\n",
    "Think of it as overriding your **global** coffee and putting a new type of coffee into your coffeemaker.\n",
    "\n",
    "### Activity\n",
    "\n",
    "Using the rules of scope you've learned so far, complete the function _puzzle_ to output the value **35**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "puzzle() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b02beceaa82e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# fill in this function call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpuzzle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: puzzle() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "# Scope Puzzle!\n",
    "x = 5\n",
    "y = 6\n",
    "z = 7\n",
    "\n",
    "def puzzle(x, y):\n",
    "    return x * y\n",
    "\n",
    "# fill in this function call\n",
    "puzzle()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control\n",
    "---\n",
    "Sometimes, we want to manipulate the flow of our code. For example, we might want our code to make decisions on its own or repeat itself a certain amount of times. By implementing control structures, we can avoid redundant code and make processes more efficient.\n",
    "\n",
    "### Conditionals\n",
    "We use **conditionals** to run certain pieces of code _if_ something is true. For example, we should only go to the grocery store _if_ we are out of peanut butter!\n",
    "\n",
    "We use **comparators** to determine whether an expression is _true_ or _false_. There are six comparators to be aware of:\n",
    "1. Equal to: ==\n",
    "2. Not equal to: !=\n",
    "3. Greater than: >\n",
    "4. Greater than or equal to: >=\n",
    "5. Less than: <\n",
    "6. Less than or equal to: <=\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE 1\n",
    "# Determine whether the following will print true or false\n",
    "# Run the code to check your answers!\n",
    "\n",
    "print(10 == 10)\n",
    "\n",
    "print(2016 < 2017)\n",
    "\n",
    "print(\"foo\" != \"bar\")\n",
    "\n",
    "print( (1+2+3+4+5) <=  (1*2*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to compare values, we can tell our computer to make decisions using the **if statement**.\n",
    "\n",
    "### If Statements\n",
    "An **if statement** takes the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please do not run this code, as it will error. It is provided as a skeleton.\n",
    "\n",
    "if (condition1):\n",
    "    # code to be executed if condition1 is true\n",
    "elif (condition2):\n",
    "    # code to be executed if condition2 is true\n",
    "else:\n",
    "    # code to be executed otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With if statements, we can control which code is executed. Check out how handy this can be in the activity below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 'Dumuzid's dream'\n",
      "He started reading 'Dumuzid's dream'\n",
      "Began paragraph 2: Grieve, grieve, O countryside, grieve! O countryside, grieve! O marshes, cry out!\n"
     ]
    }
   ],
   "source": [
    "# We want to see what part of a Sumerian text someone is reading.\n",
    "\n",
    "# Modify the variables below so you know what page someone is on after a certain time\n",
    "\n",
    "# Run the code when you're done to see the results.\n",
    "\n",
    "print(\"Read 'Dumuzid's dream'\")\n",
    "minutes = 5\n",
    "line_num = 10\n",
    "\n",
    "if (minutes >= 5):\n",
    "    print(\"He started reading 'Dumuzid's dream'\")\n",
    "    if (line_num < 5):\n",
    "        print(\"Began paragraph 1: His heart was full of tears as he went out into the countryside. The lad's heart was full of tears as he went out into the countryside...\")\n",
    "    elif (line_num >= 5 and line_num < 15):\n",
    "        print(\"Began paragraph 2: Grieve, grieve, O countryside, grieve! O countryside, grieve! O marshes, cry out!\")\n",
    "    else:\n",
    "        print(\"Began paragraph 3: -- it was a dream! He shivered -- it was sleep! He rubbed his eyes, he was terrified.\")\n",
    "else:\n",
    "    print(\"He did not have enough time to finish reading 'Dumuzid's dream'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Loops\n",
    "We can also regulate the flow of our code by repeating some action over and over. Say that we wanted to greet ten people. Instead of copying and pasting the same call to _print_ over and over again, it would be better to use a **for loop**.\n",
    "\n",
    "A basic **for loop** is written in the following order:\n",
    "- The word \"for\"\n",
    "- A name we want to give each item in a sequence\n",
    "- The word \"in\"\n",
    "- A sequence (i.e. \"range(100)\" to go through numbers 0-99\n",
    "\n",
    "For example, to greet someone ten times, we could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n",
      "hello!\n"
     ]
    }
   ],
   "source": [
    "# Run me to see \"hello!\" printed ten times!\n",
    "for i in range(10):\n",
    "    print(\"hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate over a list of number of strings. For example, let's say we have a list of tiltles from texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_1\n",
      "title_2\n",
      "title_3\n",
      "title_4\n"
     ]
    }
   ],
   "source": [
    "texts = [\"title_1\", \"title_2\", \"title_3\", \"title_4\"]\n",
    "for text in texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, for loops help us avoid redundant code and have useful capabilities.\n",
    "\n",
    "**Exercise:** Write a function that returns the concatenation of the first _n_ details about a word, where _n_ is the input to the function. Use a for loop! (Insert a \"|\" between each of the categories as well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = [\"form: dub-saŋ-ta \", \"gw: first \", \"id_text: c.0.1.1 \", \"lang: sux \", \"line_no: 1 \", \"text_name: Ur III catalogue from Nibru (N1)\"]\n",
    "def concat_first_n(n):\n",
    "    # YOUR CODE HERE\n",
    "    ...    \n",
    "\n",
    "concat_first_n(4) # Should look like =  \"form: dub-saŋ-ta; gw: first; id_text: c.0.1.1; lang: sux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table & Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "Arrays are a helpful type of datastructure. Information can easily be accessed in arrays by using indices. Earlier in this module, you have seen lists. Lists are similar to arrays, but arrays are used more often for large data sets becuase of very useful built in properties that lists do not have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nums_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # a list of integers\n",
    "nums_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) #an array of integers\n",
    "\n",
    "#For example, if we divide an array by 3 or it divides each element by 3. \n",
    "#If we tried this on the list, it would cause an error.\n",
    "\n",
    "nums_array_div3 = nums_array/3 #works for addition, subtraction, multiplication, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access specific elements in arrays by indexing. One thing to note: we always start with index 0 for the first element in any CompSci, iterable datastructure. Index 1 would give you the second element and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(nums_array[0])\n",
    "print(nums_array[len(nums_array) - 1])# we can easily print out the last element using the len function on the array\n",
    "\n",
    "#Task: print the 3rd element:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cool feature of python arrays that is not always available in other programming languages is a special notation to access multiple elements of an array at a time. Generalized: array[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums_array[1:] #gives you everything after index 1, including index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums_array[2:5] #gives you index elem at index 2 through index 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try some on your own!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pandas`\n",
    "\n",
    "`pandas` is designed to make it easier to work with structured data. Most of the analyses you might perform will likely involve using tabular data, e.g., from .csv files or relational databases (e.g., SQL). The `DataFrame` object in `pandas` is \"a two-dimensional tabular, column-oriented data structure with both row and column labels.\" Pandas is very similar to Numpy tables and is sometimes more complicated, but if you learn how to use Pandas dataframes (Pandas' version of a Numpy table), you can easily learn how to use Numpy tables, which you will see later on. \n",
    "\n",
    "If you're curious:\n",
    "\n",
    ">The `pandas` name itself is derived from *panel data*, an econometrics term for multidimensional structured data sets, and *Python data analysis* itself. After getting introduced, you can consult the full [`pandas` documentation](http://pandas.pydata.org/pandas-docs/stable/).\n",
    "\n",
    "We'll work with some data on Sumerian texts.(what words a text contains)\n",
    "\n",
    "Let's begin by importing `pandas` using the conventional abbreviation: pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('savefig', dpi=200)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['xtick.minor.size'] = 0\n",
    "plt.rcParams['ytick.minor.size'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv()` function in `pandas` allows us to easily import our data. By default, it assumes the data is comma-delimited. However, you can specify the delimiter used in your data (e.g., tab, semicolon, pipe, etc.). There are several parameters that you can specify. See the documentation [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). `read_csv()` returns a `DataFrame`.\n",
    "\n",
    "Notice that we call `read_csv()` using the `pd` abbreviation from the import statement above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anzag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an-zag-še₃</td>\n",
       "      <td>horizon</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anŋi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an-ŋi₆</td>\n",
       "      <td>eclipse</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zu</td>\n",
       "      <td>know</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>V/t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ama</td>\n",
       "      <td>mother</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tu₆</td>\n",
       "      <td>incantation</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zu-ke₄</td>\n",
       "      <td>know</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>V/t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ŋiš-gi</td>\n",
       "      <td>thicket</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tuku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tuku₄-e</td>\n",
       "      <td>rock</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>V/t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KAŠ₄</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAŠ₄</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KAŠ₄</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAŠ₄</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>me</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me₃-ke₄</td>\n",
       "      <td>battle</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mašmaš</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maš-maš</td>\n",
       "      <td>sorcerer</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>erim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erim₂</td>\n",
       "      <td>enemy</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cf extent        form           gw  id_text lang line_no  line_ref  \\\n",
       "0   dubsaŋ    NaN  dub-saŋ-ta        first  c.0.1.1  sux       1         1   \n",
       "1     Enki    NaN    {d}en-ki            1  c.0.1.1  sux       2         2   \n",
       "2      unu    NaN        unu₂     dwelling  c.0.1.1  sux       2         2   \n",
       "3      gal    NaN         gal          big  c.0.1.1  sux       2         2   \n",
       "4       ed    NaN      im-ed₃       ascend  c.0.1.1  sux       2         2   \n",
       "5    anzag    NaN  an-zag-še₃      horizon  c.0.1.1  sux       3         3   \n",
       "6     anŋi    NaN      an-ŋi₆      eclipse  c.0.1.1  sux       4         4   \n",
       "7       zu    NaN          zu         know  c.0.1.1  sux       4         4   \n",
       "8      ama    NaN         ama       mother  c.0.1.1  sux       4         4   \n",
       "9       tu    NaN         tu₆  incantation  c.0.1.1  sux       4         4   \n",
       "10      zu    NaN      zu-ke₄         know  c.0.1.1  sux       4         4   \n",
       "11      gi    NaN      ŋiš-gi      thicket  c.0.1.1  sux       5         5   \n",
       "12    tuku    NaN     tuku₄-e         rock  c.0.1.1  sux       5         5   \n",
       "13      AN    NaN          AN          NaN  c.0.1.1  sux       6         6   \n",
       "14    KAŠ₄    NaN        KAŠ₄          NaN  c.0.1.1  sux       6         6   \n",
       "15      AN    NaN          AN          NaN  c.0.1.1  sux       6         6   \n",
       "16    KAŠ₄    NaN        KAŠ₄          NaN  c.0.1.1  sux       6         6   \n",
       "17      me    NaN     me₃-ke₄       battle  c.0.1.1  sux       6         6   \n",
       "18  mašmaš    NaN     maš-maš     sorcerer  c.0.1.1  sux       7         7   \n",
       "19    erim    NaN       erim₂        enemy  c.0.1.1  sux       7         7   \n",
       "\n",
       "    pos status                         text_name version  \n",
       "0    AJ    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    DN    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2     N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3   V/i    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4   V/i    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "5     N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "6     N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "7   V/t    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "8     N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "9     N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "10  V/t    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "11    N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "12  V/t    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "13  NaN    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "14  NaN    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "15  NaN    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "16  NaN    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "17    N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "18    N    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "19    N    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = pd.read_csv('https://raw.githubusercontent.com/niekveldhuis/Digital-Assyriology/test/Scrape-etcsl/Output/alltexts.csv', index_col=0)\n",
    "all_texts = all_texts.loc[all_texts.lang == 'sux', :]\n",
    "twenty_texts = all_texts[:20] # this shortens the table to only 20 texts, so the size is not too overwhelming\n",
    "twenty_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You've created a `pandas` `DataFrame`. We can look at our data by using the `.head()` method. By default, this shows the header (column names) and the first five rows. Passing an integer, $n$, to `.head()` returns that number of rows. To see the last $n$ rows, use `.tail()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1         1   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2         2   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2         2    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2         2  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2         2  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the number of rows, you can use the `len()` function. Alternatively, you can use the `shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_texts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 rows and 12 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we're interested in the values (row) associated with a certain text,\" we can use `.loc` and an index number or the index name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cf                                     dubsaŋ\n",
       "extent                                    NaN\n",
       "form                               dub-saŋ-ta\n",
       "gw                                      first\n",
       "id_text                               c.0.1.1\n",
       "lang                                      sux\n",
       "line_no                                     1\n",
       "line_ref                                    1\n",
       "pos                                        AJ\n",
       "status                                    NaN\n",
       "text_name    Ur III catalogue from Nibru (N1)\n",
       "version                                   NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_texts.loc[0] #gets the information of the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another indexing option, `.iloc`, primarily works with integer positions. To select specific rows, we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anzag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an-zag-še₃</td>\n",
       "      <td>horizon</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anŋi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an-ŋi₆</td>\n",
       "      <td>eclipse</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tu₆</td>\n",
       "      <td>incantation</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cf extent        form           gw  id_text lang line_no  line_ref pos  \\\n",
       "1   Enki    NaN    {d}en-ki            1  c.0.1.1  sux       2         2  DN   \n",
       "5  anzag    NaN  an-zag-še₃      horizon  c.0.1.1  sux       3         3   N   \n",
       "6   anŋi    NaN      an-ŋi₆      eclipse  c.0.1.1  sux       4         4   N   \n",
       "9     tu    NaN         tu₆  incantation  c.0.1.1  sux       4         4   N   \n",
       "\n",
       "  status                         text_name version  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "5    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "6    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "9    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_texts.iloc[[1, 5, 6, 9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Read & Prep <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to be able to read and process data, so the data is clear and easy to use. With well-organized data, exploring patterns in data is easily accomplished. Here, you will learn some methods to clean up and filter data, make Document Term Matrices (DTM), and find differences between particular data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:13:55.837074Z",
     "start_time": "2018-04-02T07:13:55.595431Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first step we take is to read in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:52.341299Z",
     "start_time": "2018-04-02T07:09:50.072264Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1         1   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2         2   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2         2    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2         2  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2         2  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex = pd.read_csv('https://raw.githubusercontent.com/niekveldhuis/Digital-Assyriology/test/Scrape-etcsl/Output/alltexts.csv')\n",
    "alltex = alltex.drop(alltex.columns[0], axis=1) #drop the first column, which is just the row numbers from the csv\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also import the new text we'll be analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:52.375890Z",
     "start_time": "2018-04-02T07:09:52.343806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>text_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nin</td>\n",
       "      <td>lady</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>iddindaganAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nun</td>\n",
       "      <td>prince</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>iddindaganAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal-e-ne</td>\n",
       "      <td>big</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V/i</td>\n",
       "      <td>iddindaganAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saŋ</td>\n",
       "      <td>head</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>iddindaganAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>il</td>\n",
       "      <td>NaN</td>\n",
       "      <td>il₂</td>\n",
       "      <td>raise</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V/t</td>\n",
       "      <td>iddindaganAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cf  extent      form      gw id_text lang  line_no  line_ref  pos  \\\n",
       "0  nin     NaN       nin    lady     NEW  sux      NaN       NaN    N   \n",
       "1  nun     NaN       nun  prince     NEW  sux      NaN       NaN    N   \n",
       "2  gal     NaN  gal-e-ne     big     NEW  sux      NaN       NaN  V/i   \n",
       "3  saŋ     NaN       saŋ    head     NEW  sux      NaN       NaN    N   \n",
       "4   il     NaN       il₂   raise     NEW  sux      NaN       NaN  V/t   \n",
       "\n",
       "      text_name  \n",
       "0  iddindaganAB  \n",
       "1  iddindaganAB  \n",
       "2  iddindaganAB  \n",
       "3  iddindaganAB  \n",
       "4  iddindaganAB  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtex = pd.read_csv(\"iddindaganAB.csv\", index_col=0).loc[:, \n",
    "                                                          [\"cf\", \"extent\", \"form\", \"gw\", \n",
    "                                                           \"id_text\", \"lang\", \"line_no\",\n",
    "                                                           \"line_ref\", \"pos\"\n",
    "                                                          ]]\n",
    "newtex[\"id_text\"] = np.repeat(\"NEW\", newtex.shape[0])\n",
    "newtex[\"text_name\"] = np.repeat(\"iddindaganAB\", newtex.shape[0])\n",
    "newtex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the two together to get a full dataframe of our texts. Notice the head looks exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:52.460114Z",
     "start_time": "2018-04-02T07:09:52.377896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2       2.0  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex = pd.concat([alltex,newtex])\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the tail now consists of entries from the new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:53.338951Z",
     "start_time": "2018-04-02T07:09:53.319401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>sug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sug₄-ga</td>\n",
       "      <td>empty</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iddindaganAB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>kišuš</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ki-šuš₂-bi-im</td>\n",
       "      <td>notation</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iddindaganAB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>zamin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zag-mi₂</td>\n",
       "      <td>lyre</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iddindaganAB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>dug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dug₃-ga</td>\n",
       "      <td>good</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iddindaganAB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Inanak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}inana-kam</td>\n",
       "      <td>1</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iddindaganAB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cf extent           form        gw id_text lang line_no  line_ref  \\\n",
       "667     sug    NaN        sug₄-ga     empty     NEW  sux     NaN       NaN   \n",
       "668   kišuš    NaN  ki-šuš₂-bi-im  notation     NEW  sux     NaN       NaN   \n",
       "669   zamin    NaN        zag-mi₂      lyre     NEW  sux     NaN       NaN   \n",
       "670     dug    NaN        dug₃-ga      good     NEW  sux     NaN       NaN   \n",
       "671  Inanak    NaN   {d}inana-kam         1     NEW  sux     NaN       NaN   \n",
       "\n",
       "     pos status     text_name version  \n",
       "667  V/i    NaN  iddindaganAB     NaN  \n",
       "668    N    NaN  iddindaganAB     NaN  \n",
       "669    N    NaN  iddindaganAB     NaN  \n",
       "670  V/i    NaN  iddindaganAB     NaN  \n",
       "671   DN    NaN  iddindaganAB     NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we filter out languages we don't care about. To do this, we look at the 'lang' column, and select only those rows where the 'lang' value starts with 'sux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:54.827547Z",
     "start_time": "2018-04-02T07:09:54.702211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2       2.0  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex = alltex.loc[[str(i)[:3] == 'sux' for i in alltex.lang], :]\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'd like to filter out the rows that have nulls in the cf, gw, or pos columns. In other words, we keep columns that *don't* have NA in gw AND *don't* have NA in form AND *don't* have NA in pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:57.653229Z",
     "start_time": "2018-04-02T07:09:57.650222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefilter = alltex #we'll use this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:58.280899Z",
     "start_time": "2018-04-02T07:09:58.223747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2       2.0  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex = alltex.loc[np.logical_and(~pd.isnull(alltex.gw),\n",
    "                         np.logical_and(~pd.isnull(alltex.form),\n",
    "                                       ~pd.isnull(alltex.pos))\n",
    "                         )]\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I filter out \"X\" and \"(X)\". We want rows where gw is *not* X or (X) AND form is *not* X or (X) AND pos is *not* X or (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:59.063494Z",
     "start_time": "2018-04-02T07:09:59.059984Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xstrings = [\"X\", \"(X)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:09:59.478097Z",
     "start_time": "2018-04-02T07:09:59.415432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2       2.0  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex = alltex.loc[np.logical_and(~np.in1d(alltex.gw, xstrings) ,\n",
    "                         np.logical_and(~np.in1d(alltex.form, xstrings),\n",
    "                                       ~np.in1d(alltex.pos, xstrings))\n",
    "                         )]\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're ready to start lemmatizing, or creating the \"terms\". Terms look like this for each word: \n",
    "\n",
    "cf + '[' + gw + ']' + pos \n",
    "\n",
    "To do this, we'll paste together the appropriate column entries for each row, and create a new column called \"Term\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:10:41.014499Z",
     "start_time": "2018-04-02T07:10:40.867609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dubsaŋ[first]AJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enki[1]DN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu[dwelling]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal[big]V/i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ed[ascend]V/i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2       2.0  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "\n",
       "  status                         text_name version             Term  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  dubsaŋ[first]AJ  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN        Enki[1]DN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN   unu[dwelling]N  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN      gal[big]V/i  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN    ed[ascend]V/i  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex['Term'] = alltex.cf.str.cat(others = alltex.gw, sep = \"[\").str.cat(others = alltex.pos, sep = \"]\")\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with these terms, we can filter out stop words and \"stop docs\".\n",
    "* Stop word: A term to common in the language to be useful for classification; examples in English include the articles (a, an, the), as they are used in nearly every document and thus are not useful for distinguishing between documents.\n",
    "* \"Stop doc\": A document that we would not like to include for whatever reason, such as being too short\n",
    "\n",
    "The things we want to filter out could change, so I'll write a function to do this filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:10:42.501471Z",
     "start_time": "2018-04-02T07:10:42.497444Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter(table, stopwords = [], stopdocs = []):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        table: Pandas dataframe\n",
    "            The table to modify/filter.\n",
    "        stopwords: Arraylike, Strings\n",
    "            A collection of strings of terms to filter out\n",
    "        stopdocs: Arraylike, Strings\n",
    "    Returns a table without the terms and documents specified\n",
    "    \"\"\"\n",
    "    return table.loc[np.logical_and(~np.in1d(table.Term, stopwords), ~np.in1d(table.id_text, stopdocs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:10:42.647843Z",
     "start_time": "2018-04-02T07:10:42.638318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['dug[speak]V/t', 'ki[place]N', 'šu[hand]N', 'gal[big]V/i',\n",
       "        'lu[person]N', 'e[house]N', 'ŋar[place]V/t', 'šag[heart]N',\n",
       "        'kur[mountain]N', 'lugal[king]N', 'ud[sun]N', 'Enlil[1]DN',\n",
       "        'igi[eye]N', 'e[leave]V/i', 'kug[pure]V/i', 'an[sky]N',\n",
       "        'saŋ[head]N', 'ak[do]V/t', 'gub[stand]V/i', 'en[lord]N',\n",
       "        'ŋal[be]V/i'], dtype=object),\n",
       " array(['c.0.2.05', 'c.0.2.12', 'c.2.4.1.8', 'c.2.4.2.12', 'c.2.4.2.23',\n",
       "        'c.2.4.4.5', 'c.2.4.4.9', 'c.2.5.2.3', 'c.2.5.4.16', 'c.2.5.5.8',\n",
       "        'c.2.6.9.a', 'c.2.8.2.5', 'c.2.8.3.4', 'c.2.8.3.7', 'c.2.8.3.8',\n",
       "        'c.2.99.b', 'c.2.99.c', 'c.2.99.d', 'c.3.1.10', 'c.3.1.13.1',\n",
       "        'c.3.2.01', 'c.3.3.06', 'c.3.3.07', 'c.3.3.12', 'c.3.3.20',\n",
       "        'c.3.3.27', 'c.4.08.12', 'c.4.08.13', 'c.4.08.22', 'c.4.13.b',\n",
       "        'c.4.13.d', 'c.4.19.4', 'c.4.22.3', 'c.4.27.a', 'c.4.30.1',\n",
       "        'c.5.7.3', 'c.5.7.a', 'c.6.2.4'], dtype=object))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = np.array(pd.read_csv(\"stopwords_top21.txt\", header=None)[0])\n",
    "stopdocs = np.array(pd.read_csv(\"stopdocuments_less50.txt\", header = None)[0])\n",
    "stopwords,stopdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:10:43.054926Z",
     "start_time": "2018-04-02T07:10:42.818297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dubsaŋ[first]AJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enki[1]DN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu[dwelling]N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ed[ascend]V/i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anzag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an-zag-še₃</td>\n",
       "      <td>horizon</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anzag[horizon]N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "5   anzag    NaN  an-zag-še₃   horizon  c.0.1.1  sux       3       3.0    N   \n",
       "\n",
       "  status                         text_name version             Term  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  dubsaŋ[first]AJ  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN        Enki[1]DN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN   unu[dwelling]N  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN    ed[ascend]V/i  \n",
       "5    NaN  Ur III catalogue from Nibru (N1)     NaN  anzag[horizon]N  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltex = filter(alltex, stopwords=stopwords, stopdocs = stopdocs)\n",
    "alltex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are ready to create a tfidf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:10:45.889203Z",
     "start_time": "2018-04-02T07:10:45.749831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4335,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(alltex.Term).shape #this gives us an idea of how many columns we should see in the tfidf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to numerically represent our data in a useful way. For this purpose, we create a document-term matrix: a matrix with terms as the column labels, and documents as the rows. More generally, a document is split up into \"tokens\"- words, or group of words (ie, ngrams) that can help classify a document. These tokens allow us to basically represent documents as points in an N-d space, where N is the number of unique tokens used across documents. For example, if I had document A = \"hello hello bye there\" and Document B = \"there there hello hello\", I could represent the first as the point (2, 1, 1) and the second as (2, 0, 2), with the order being (# of hellos, # of byes, # of theres). One could imagine, then, a matrix with each document as a row and each term as a column; the rows of this matrix would then basically look like the lists of numbers just given. The length of these rows is the number o unique terms across all the documents in our corpus.\n",
    "\n",
    "In a document term matrix (DTM)The value in the cell at position (document, term) will have a number corresponding to how frequently that word appears in the document. However, if the word is very common across all our documents, it won't be as helpful in classification. So we'd like to \"penalize\" words that appear too frequently, where \"too frequently\" is based on how many documents it appears in. Wanting a measure these two things\n",
    "* How often some term t appears in a particular document d\n",
    "* How often this term t appears in all documents (and penalize for this)\n",
    "leads us to the TFIDF (term frequency inverse document frequency measure).\n",
    "\n",
    "We calculate a TFIDF by the formula\n",
    "$$\n",
    "tfidf(t, d, D) = tf(t,d)\\cdot idf(t,D)\n",
    "$$\n",
    "where $t$ is the term, $d$ is the document, and $D$ is the corpus.\n",
    "Here, $tf(t,d)$ is just going to be a function returning the raw count of term t in document d. The idf will be  \n",
    "$$\n",
    "log\\frac{1 + N}{1 + n_t} + 1\n",
    "$$\n",
    "where N is the number of documents in the corpus and n_t is the number of docs where the term appears (formally $|{d \\in D: t \\in d}|$). The +1s in the log are to safeguard against log(0) or division by 0 errors, while the +1 outside ensures a positive value.\n",
    "\n",
    "This means the overall expression for tfidf is\n",
    "$$\n",
    "f_{t,d}\\cdot ln(\\frac{N}{n_t})\n",
    "$$\n",
    "The full workings of the following procedure are documented here: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create this tfidf, we use sklearn's vectorizer. But before doing that, we need to represent our corpus as a list of documents, which it currently is not (it's currently split up in our dataframe). To do this, we aggregate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:12:33.861687Z",
     "start_time": "2018-04-02T07:12:33.599490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>lang</th>\n",
       "      <th>pos</th>\n",
       "      <th>text_name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEW</th>\n",
       "      <td>nin nun il dirig Inanak uŋ šar šeŋ ulu zipaŋ n...</td>\n",
       "      <td>nin nun il₂ dirig-ga {d}inana uŋ₃ šar₂-ra šeŋ₃...</td>\n",
       "      <td>lady prince raise exceed 1 people 3600 rain wi...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>N N V/t V/i DN N NU V/i N N N V/t V/t N QP V/t...</td>\n",
       "      <td>iddindaganAB iddindaganAB iddindaganAB iddinda...</td>\n",
       "      <td>nin[lady]N nun[prince]N il[raise]V/t dirig[exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.1</th>\n",
       "      <td>dubsaŋ Enki unu ed anzag anŋi zu ama tu zu gi ...</td>\n",
       "      <td>dub-saŋ-ta {d}en-ki unu₂ im-ed₃ an-zag-še₃ an-...</td>\n",
       "      <td>first 1 dwelling ascend horizon eclipse know m...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>AJ DN N V/i N N V/t N N V/t N V/t N N N V/i N ...</td>\n",
       "      <td>Ur III catalogue from Nibru (N1) Ur III catalo...</td>\n",
       "      <td>dubsaŋ[first]AJ Enki[1]DN unu[dwelling]N ed[as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.2</th>\n",
       "      <td>diŋir šembizida dar kur mete gud banda šerzid ...</td>\n",
       "      <td>diŋir šembi₂-zid-da dar-a nu-kur₂ me-te-bi gud...</td>\n",
       "      <td>deity kohl split different appropriate-thing o...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>N N V/t V/i N N V/i N N V/i N N N V/i N N NU V...</td>\n",
       "      <td>Ur III catalogue at Yale (Y1) Ur III catalogue...</td>\n",
       "      <td>diŋir[deity]N šembizida[kohl]N dar[split]V/t k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.01</th>\n",
       "      <td>mi niŋdu nin me šar sud nam nun re innin me hu...</td>\n",
       "      <td>mi₂ niŋ₂-du₇-e nin me šar₂-ra su₃-ra₂-še₃ nam₂...</td>\n",
       "      <td>cvne appropriate-thing lady Being 3600 distant...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>N N N N NU V/i N N DP N N V/i N V/i V/i V/i N ...</td>\n",
       "      <td>OB catalogue from Nibru (N2) OB catalogue from...</td>\n",
       "      <td>mi[cvne]N niŋdu[appropriate-thing]N nin[lady]N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.02</th>\n",
       "      <td>sud nam nun re innin me huš ud huš til hursaŋ ...</td>\n",
       "      <td>su₃-ra₂-še₃ nam₂ nun-e re-a in-nin me huš-a ud...</td>\n",
       "      <td>distant lord prince that lady Being reddish st...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>V/i N N DP N N V/i N V/i V/i N N V/i N N DP DP...</td>\n",
       "      <td>OB catalogue in the Louvre (L) OB catalogue in...</td>\n",
       "      <td>sud[distant]V/i nam[lord]N nun[prince]N re[tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         cf  \\\n",
       "id_text                                                       \n",
       "NEW       nin nun il dirig Inanak uŋ šar šeŋ ulu zipaŋ n...   \n",
       "c.0.1.1   dubsaŋ Enki unu ed anzag anŋi zu ama tu zu gi ...   \n",
       "c.0.1.2   diŋir šembizida dar kur mete gud banda šerzid ...   \n",
       "c.0.2.01  mi niŋdu nin me šar sud nam nun re innin me hu...   \n",
       "c.0.2.02  sud nam nun re innin me huš ud huš til hursaŋ ...   \n",
       "\n",
       "                                                       form  \\\n",
       "id_text                                                       \n",
       "NEW       nin nun il₂ dirig-ga {d}inana uŋ₃ šar₂-ra šeŋ₃...   \n",
       "c.0.1.1   dub-saŋ-ta {d}en-ki unu₂ im-ed₃ an-zag-še₃ an-...   \n",
       "c.0.1.2   diŋir šembi₂-zid-da dar-a nu-kur₂ me-te-bi gud...   \n",
       "c.0.2.01  mi₂ niŋ₂-du₇-e nin me šar₂-ra su₃-ra₂-še₃ nam₂...   \n",
       "c.0.2.02  su₃-ra₂-še₃ nam₂ nun-e re-a in-nin me huš-a ud...   \n",
       "\n",
       "                                                         gw  \\\n",
       "id_text                                                       \n",
       "NEW       lady prince raise exceed 1 people 3600 rain wi...   \n",
       "c.0.1.1   first 1 dwelling ascend horizon eclipse know m...   \n",
       "c.0.1.2   deity kohl split different appropriate-thing o...   \n",
       "c.0.2.01  cvne appropriate-thing lady Being 3600 distant...   \n",
       "c.0.2.02  distant lord prince that lady Being reddish st...   \n",
       "\n",
       "                                                       lang  \\\n",
       "id_text                                                       \n",
       "NEW       sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.1.1   sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.1.2   sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.2.01  sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.2.02  sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "\n",
       "                                                        pos  \\\n",
       "id_text                                                       \n",
       "NEW       N N V/t V/i DN N NU V/i N N N V/t V/t N QP V/t...   \n",
       "c.0.1.1   AJ DN N V/i N N V/t N N V/t N V/t N N N V/i N ...   \n",
       "c.0.1.2   N N V/t V/i N N V/i N N V/i N N N V/i N N NU V...   \n",
       "c.0.2.01  N N N N NU V/i N N DP N N V/i N V/i V/i V/i N ...   \n",
       "c.0.2.02  V/i N N DP N N V/i N V/i V/i N N V/i N N DP DP...   \n",
       "\n",
       "                                                  text_name  \\\n",
       "id_text                                                       \n",
       "NEW       iddindaganAB iddindaganAB iddindaganAB iddinda...   \n",
       "c.0.1.1   Ur III catalogue from Nibru (N1) Ur III catalo...   \n",
       "c.0.1.2   Ur III catalogue at Yale (Y1) Ur III catalogue...   \n",
       "c.0.2.01  OB catalogue from Nibru (N2) OB catalogue from...   \n",
       "c.0.2.02  OB catalogue in the Louvre (L) OB catalogue in...   \n",
       "\n",
       "                                                       Term  \n",
       "id_text                                                      \n",
       "NEW       nin[lady]N nun[prince]N il[raise]V/t dirig[exc...  \n",
       "c.0.1.1   dubsaŋ[first]AJ Enki[1]DN unu[dwelling]N ed[as...  \n",
       "c.0.1.2   diŋir[deity]N šembizida[kohl]N dar[split]V/t k...  \n",
       "c.0.2.01  mi[cvne]N niŋdu[appropriate-thing]N nin[lady]N...  \n",
       "c.0.2.02  sud[distant]V/i nam[lord]N nun[prince]N re[tha...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = alltex.groupby(\"id_text\").aggregate(\" \".join) #this line of code lumps together all documents' terms together, and joins them as a single space separated string\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by just making a regular term matrix: just count up the number of times we see a word in a particular document. Sklearn's countvectorizer takes care of this nicely. Below, we create a countvectorizer object. This is essentially like a really flexible tool ()like a Swiss army knife, perhaps) that we've just created in code. The parameters that are passed in sort of \"configure\" our Swiss army knife to behave in a particular way. Then, in later cells, we use a particular tool in our Swiss army knife to help us accomplish the end goal of creating a DTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we've initialized a count vectorizer object. Here, the second argument is fairly straightforward to understand: when we apply this count vectorizer to something we want to turn into a DTM, we leave the capitalization as is. \n",
    "The first is a bit more strange. This is a string that we've set that helps the CV object recognize what we want to be a token (a term, in this case). The default behavior for this object is just to treat all punctuation and whitespace as separators. So, it might just end up separating our grouped terms into separate tokens, which is not idea. This string passed in for token_pattern tells the count vectorizer that our tokens should 1) have at least 1 character, and 2) not contain any spaces. The CV then separates a string passed in into chunk, each chunk fulfiling the criteria set by the string. Basically, this means that we've told the count vectorizer to only separate at spaces and nothing else. This particular string searching is known as a regular experssion (regex), which you can learn more about and play around with here: https://regexr.com/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:12:39.730981Z",
     "start_time": "2018-04-02T07:12:39.728475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(token_pattern='[^ ]+', lowercase = False) #initialize a count vectorizer object with correct tokenization for this term format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, below, we've called upon one of the \"tools\" of the Swiss army knife; .fit_transform, which takes in a list of strings, interprets each string as a document, and spits out the DTM based on this interpretation. It splits apart each document based on the toke pattern given above, and doesn't force lowercase. By doing this, we produce a dtm object. This has a .to_array() method which we use to represent it as a numpy array. The array is then easily converted to a dataframe; noting further that the rows will be each document (the names of which can be obtained from the original dataframe), and that the columns will be the tokens identified by the CV object. The result is displayed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix is quite simple in that it shows us a very intutitive picture; each cell is just the number of times a word appeared in a particular document; like šusi[finger]N showed up thrice in the document labeled c.6.2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:12:58.934396Z",
     "start_time": "2018-04-02T07:12:58.815579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-kam-ma[1st]NU</th>\n",
       "      <th>1/2[1/2]NU</th>\n",
       "      <th>1/3[1/3]NU</th>\n",
       "      <th>10-kam-ma[10th]NU</th>\n",
       "      <th>1000[1000]NU</th>\n",
       "      <th>100[100]NU</th>\n",
       "      <th>108000[108000]NU</th>\n",
       "      <th>1080[1080]NU</th>\n",
       "      <th>108[108]NU</th>\n",
       "      <th>10[10]NU</th>\n",
       "      <th>...</th>\n",
       "      <th>šusi[finger]N</th>\n",
       "      <th>šuteŋ[accept]V/t</th>\n",
       "      <th>šutubur[mixture]N</th>\n",
       "      <th>šutug[reed-hut]N</th>\n",
       "      <th>šutum[storehouse]N</th>\n",
       "      <th>šutur[garment]N</th>\n",
       "      <th>šuš[cover]V/t</th>\n",
       "      <th>šuʾi[barber]N</th>\n",
       "      <th>šuʾu[stone]N</th>\n",
       "      <th>šuʾura[goose]N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEW</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1-kam-ma[1st]NU  1/2[1/2]NU  1/3[1/3]NU  10-kam-ma[10th]NU  \\\n",
       "id_text                                                                \n",
       "NEW                     0           0           0                  0   \n",
       "c.0.1.1                 2           0           0                  0   \n",
       "c.0.1.2                 0           0           0                  0   \n",
       "c.0.2.01                0           0           0                  0   \n",
       "c.0.2.02                0           0           0                  0   \n",
       "\n",
       "          1000[1000]NU  100[100]NU  108000[108000]NU  1080[1080]NU  \\\n",
       "id_text                                                              \n",
       "NEW                  0           0                 0             0   \n",
       "c.0.1.1              0           0                 0             0   \n",
       "c.0.1.2              0           0                 0             0   \n",
       "c.0.2.01             0           0                 0             0   \n",
       "c.0.2.02             0           0                 0             0   \n",
       "\n",
       "          108[108]NU  10[10]NU       ...        šusi[finger]N  \\\n",
       "id_text                              ...                        \n",
       "NEW                0         0       ...                    0   \n",
       "c.0.1.1            0         0       ...                    0   \n",
       "c.0.1.2            0         1       ...                    0   \n",
       "c.0.2.01           0         0       ...                    0   \n",
       "c.0.2.02           0         0       ...                    0   \n",
       "\n",
       "          šuteŋ[accept]V/t  šutubur[mixture]N  šutug[reed-hut]N  \\\n",
       "id_text                                                           \n",
       "NEW                      0                  0                 0   \n",
       "c.0.1.1                  0                  0                 0   \n",
       "c.0.1.2                  0                  0                 0   \n",
       "c.0.2.01                 0                  0                 0   \n",
       "c.0.2.02                 0                  0                 0   \n",
       "\n",
       "          šutum[storehouse]N  šutur[garment]N  šuš[cover]V/t  šuʾi[barber]N  \\\n",
       "id_text                                                                       \n",
       "NEW                        0                0              0              0   \n",
       "c.0.1.1                    0                0              0              0   \n",
       "c.0.1.2                    0                0              0              0   \n",
       "c.0.2.01                   0                0              0              0   \n",
       "c.0.2.02                   0                0              0              0   \n",
       "\n",
       "          šuʾu[stone]N  šuʾura[goose]N  \n",
       "id_text                                 \n",
       "NEW                  0               0  \n",
       "c.0.1.1              0               0  \n",
       "c.0.1.2              0               0  \n",
       "c.0.2.01             0               0  \n",
       "c.0.2.02             0               0  \n",
       "\n",
       "[5 rows x 4335 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = cv.fit_transform(list(grouped.Term))\n",
    "pd.DataFrame(dtm.toarray(), columns=cv.get_feature_names(), index=grouped.index).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in hand, we then want to transform it such that we have the inverse weighting discussed above; weight the words so that words appearing more frequently aren't as big of a factor. This is accomplished by defining the transformer on the first line below, then using the transformer to transform the raw counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:13:14.135353Z",
     "start_time": "2018-04-02T07:13:14.126830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 4335)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = TfidfTransformer(use_idf=True)\n",
    "dtm_tf = tt.fit_transform(dtm)\n",
    "dtm_tf.shape #357 docs, 4335 unique terms, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:13:23.009996Z",
     "start_time": "2018-04-02T07:13:22.974401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-kam-ma[1st]NU</th>\n",
       "      <th>1/2[1/2]NU</th>\n",
       "      <th>1/3[1/3]NU</th>\n",
       "      <th>10-kam-ma[10th]NU</th>\n",
       "      <th>1000[1000]NU</th>\n",
       "      <th>100[100]NU</th>\n",
       "      <th>108000[108000]NU</th>\n",
       "      <th>1080[1080]NU</th>\n",
       "      <th>108[108]NU</th>\n",
       "      <th>10[10]NU</th>\n",
       "      <th>...</th>\n",
       "      <th>šusi[finger]N</th>\n",
       "      <th>šuteŋ[accept]V/t</th>\n",
       "      <th>šutubur[mixture]N</th>\n",
       "      <th>šutug[reed-hut]N</th>\n",
       "      <th>šutum[storehouse]N</th>\n",
       "      <th>šutur[garment]N</th>\n",
       "      <th>šuš[cover]V/t</th>\n",
       "      <th>šuʾi[barber]N</th>\n",
       "      <th>šuʾu[stone]N</th>\n",
       "      <th>šuʾura[goose]N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEW</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.1</th>\n",
       "      <td>0.22879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.01</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.02</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1-kam-ma[1st]NU  1/2[1/2]NU  1/3[1/3]NU  10-kam-ma[10th]NU  \\\n",
       "id_text                                                                \n",
       "NEW               0.00000         0.0         0.0                0.0   \n",
       "c.0.1.1           0.22879         0.0         0.0                0.0   \n",
       "c.0.1.2           0.00000         0.0         0.0                0.0   \n",
       "c.0.2.01          0.00000         0.0         0.0                0.0   \n",
       "c.0.2.02          0.00000         0.0         0.0                0.0   \n",
       "\n",
       "          1000[1000]NU  100[100]NU  108000[108000]NU  1080[1080]NU  \\\n",
       "id_text                                                              \n",
       "NEW                0.0         0.0               0.0           0.0   \n",
       "c.0.1.1            0.0         0.0               0.0           0.0   \n",
       "c.0.1.2            0.0         0.0               0.0           0.0   \n",
       "c.0.2.01           0.0         0.0               0.0           0.0   \n",
       "c.0.2.02           0.0         0.0               0.0           0.0   \n",
       "\n",
       "          108[108]NU  10[10]NU       ...        šusi[finger]N  \\\n",
       "id_text                              ...                        \n",
       "NEW              0.0  0.000000       ...                  0.0   \n",
       "c.0.1.1          0.0  0.000000       ...                  0.0   \n",
       "c.0.1.2          0.0  0.092156       ...                  0.0   \n",
       "c.0.2.01         0.0  0.000000       ...                  0.0   \n",
       "c.0.2.02         0.0  0.000000       ...                  0.0   \n",
       "\n",
       "          šuteŋ[accept]V/t  šutubur[mixture]N  šutug[reed-hut]N  \\\n",
       "id_text                                                           \n",
       "NEW                    0.0                0.0               0.0   \n",
       "c.0.1.1                0.0                0.0               0.0   \n",
       "c.0.1.2                0.0                0.0               0.0   \n",
       "c.0.2.01               0.0                0.0               0.0   \n",
       "c.0.2.02               0.0                0.0               0.0   \n",
       "\n",
       "          šutum[storehouse]N  šutur[garment]N  šuš[cover]V/t  šuʾi[barber]N  \\\n",
       "id_text                                                                       \n",
       "NEW                      0.0              0.0            0.0            0.0   \n",
       "c.0.1.1                  0.0              0.0            0.0            0.0   \n",
       "c.0.1.2                  0.0              0.0            0.0            0.0   \n",
       "c.0.2.01                 0.0              0.0            0.0            0.0   \n",
       "c.0.2.02                 0.0              0.0            0.0            0.0   \n",
       "\n",
       "          šuʾu[stone]N  šuʾura[goose]N  \n",
       "id_text                                 \n",
       "NEW                0.0             0.0  \n",
       "c.0.1.1            0.0             0.0  \n",
       "c.0.1.2            0.0             0.0  \n",
       "c.0.2.01           0.0             0.0  \n",
       "c.0.2.02           0.0             0.0  \n",
       "\n",
       "[5 rows x 4335 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pd.DataFrame(dtm_tf.toarray(), columns=cv.get_feature_names(), index=grouped.index)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences between documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with a TFIDF matrix, we can begin assessing similarity of documents by treating each row of this matrix as a respresentation of that document (specifically, as a vector) in N dimensional Euclidian space, where N is the number of features (words). Similarity of documents can be interpreted as being the distance between documents in this N space. Here, we will be interested in two measures of distance: cosine distance and Euclidian (L2) distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start of with cosine similarity; it's a bit easier to think about. A cosine similarity (https://en.wikipedia.org/wiki/Cosine_similarity) is defined as the $cos\\theta$ of two vectors, and can be calculated from the dot product of two vectors. Thus, to determine cosine similarity between two documents, we must calculate the dot products of their vector representations. \n",
    "\n",
    "Suppose we have a vector space with n dimensions $\\mathbb{V_n}$ (think of the regular 2d Euclidian plane as  $\\mathbb{V_2}$), and vectors $\\boldsymbol{X},\\boldsymbol{Y} \\in \\mathbb{V_n}$. We can represent $\\boldsymbol{X}$ and $\\boldsymbol{Y}$ as column vectors of size n:\n",
    "$$\n",
    "\\boldsymbol{X} = \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{n}\n",
    "         \\end{bmatrix}, \n",
    "\\boldsymbol{Y} = \\begin{bmatrix}\n",
    "           y_{1} \\\\\n",
    "           y_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           y_{n}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then, the dot product of these two vectors is defined as \n",
    "\n",
    "$$\n",
    "\\boldsymbol{X}\\cdot \\boldsymbol{Y} = \n",
    "           x_{1}y_{1} +\n",
    "           x_{2}y_{2} +\n",
    "           \\dots +\n",
    "           x_{n}y_{n}\n",
    "$$\n",
    "\n",
    "The geometric intepretation of the dot product is defined as follows: \n",
    "$$\n",
    "\\boldsymbol{X}\\cdot\\boldsymbol{Y} = |\\boldsymbol{X}||\\boldsymbol{Y}|cos\\theta \n",
    "$$\n",
    "where $|\\boldsymbol{X}|$ and $|\\boldsymbol{Y}|$ are the so-called \"norms\" of the vectors (essentially, the lengths of the vectors). \n",
    "These norms are defined as the square root of the dot product of a vector with itself, so \n",
    "$$|\\boldsymbol{X}| = \\sqrt{\\boldsymbol{X}\\cdot \\boldsymbol{X} }\n",
    "           =\\sqrt{x_{1}x_{1} +\n",
    "           x_{2}x_{2} +\n",
    "           \\dots +\n",
    "           x_{n}x_{n}}$$\n",
    "Then, we can solve for $cos \\theta$\n",
    "$$\n",
    "cos \\theta = \\frac{\\boldsymbol{X}\\cdot\\boldsymbol{Y}}{\\sqrt{|\\boldsymbol{X}|}\\sqrt{|\\boldsymbol{Y}|}}  \n",
    "$$\n",
    "In other words, cosine similarity is \n",
    "$$\n",
    "\\frac{\\boldsymbol{X}\\cdot\\boldsymbol{Y}}{(\\boldsymbol{X}\\cdot\\boldsymbol{X})(\\boldsymbol{Y}\\cdot\\boldsymbol{Y})} \n",
    "=    \\frac{x_{1}y_{1} +\n",
    "           x_{2}y_{2} +\n",
    "           \\dots +\n",
    "           x_{n}y_{n}}\n",
    "           {\n",
    "           \\sqrt{(x_{1}x_{1} +\n",
    "           x_{2}x_{2} +\n",
    "           \\dots +\n",
    "           x_{n}x_{n})}\n",
    "           \\sqrt{(y_{1}y_{1} +\n",
    "           y_{2}y_{2} +\n",
    "           \\dots +\n",
    "           y_{n}y_{n})}\n",
    "           }\n",
    "$$\n",
    "Finally, **Cosine distance is simply 1 - the cosine similarity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a cosine distance, we can use scipy.spacial.disance's cosine function. It takes two arrays of the same length, and returns the cosine distance between the two:\n",
    "\n",
    "`>> cosine(arr1, arr2)`\n",
    "\n",
    "This returns some number between 0 and 1. Why does it return 0 and 1? Basically, you can either have two documents be completely disparate (cosine distance of 1), which comes from  or they can be completely the same (cosine distance of 0). Thinking in terms of cosine similarity, it has similarity 0 when they're disparate, and 1 when it's the same document. You can think of it mathematically in the form above; if $\\boldsymbol{X}=\\boldsymbol{Y}$, then the cosine is just its square divided by itself, which would yield 1. Then, it's logical that being completely dissimilar would yield 0. Of course, this also makes sense by the rule of dot products; if two vectors are orthogonal, then they have no overlap (here, overlap is highly analogous to similarity)and yield a dot product of 0. \n",
    "\n",
    "A quick refresher on the cosine is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:13:33.019989Z",
     "start_time": "2018-04-02T07:13:32.972863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11022302463e-16\n",
      "2.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "#some demos\n",
    "test1 = np.arange(10)\n",
    "test2 = 3 * test1\n",
    "test3 = -1 * test1\n",
    "test4 = np.zeros(10)\n",
    "test4[0] = 1\n",
    "test5 = np.zeros(10)\n",
    "test5[1] = 1\n",
    "print(cosine(test1, test2)) #should be 1 - 1 = 0, 1 - cosine of 0\n",
    "print(cosine(test1, test3)) #should be 1 - (-1) = 2, 1 - cosine of pi\n",
    "print(cosine(test4, test5)) #should be 1 , 1 - cosine of pi/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mathematical intuition doesn't make sense, here's a geometric motivation. Below is a tool to visualize cosine distance. This is for a 2d space, so basically you'd be looking at a classification between documents using just two words to differentiate them. Take a look at how the cosine similarity and cosine distance change as you change the each vector (remember, each vector represents the document). As you change the angle between them (meaning the documents are more separated, and thus more different), how does the cosine similarity and distance change? Another thing to do is to compare two situations; when a short vector and a long vector make the same angle as a long vector and a long vector. What's the relationship between the angles produced in these two cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:13:34.223359Z",
     "start_time": "2018-04-02T07:13:34.220349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bound = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:14:02.815367Z",
     "start_time": "2018-04-02T07:14:02.550162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c365a1d9f757425398865a574c099ca8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def f(doc1word1, doc1word2, doc2word1, doc2word2):\n",
    "    fig, ax = plt.subplots(figsize = (8,8))\n",
    "    circle1 = plt.Circle((0, 0), bound/5, fill = False)\n",
    "    arrow1 = plt.arrow(x=0, y= 0, dx = doc1word1, dy = doc1word2, width = bound/300, length_includes_head = True, color = '#003262')\n",
    "    arrow2 = plt.arrow(x=0, y= 0, dx = doc2word1, dy = doc2word2, width = bound/300, length_includes_head = True, color = '#FDB515')\n",
    "    ax.add_artist(circle1)\n",
    "    plt.xlim(0, bound)\n",
    "    plt.xlabel(\"tfidf of word 1 for doc\")\n",
    "    plt.ylabel(\"tfidf of word 2 for doc\")\n",
    "    plt.ylim(0, bound)\n",
    "    plt.legend([arrow1,arrow2], ['Doc 1','Doc2'])\n",
    "    plt.show()\n",
    "    print(\"Cosine distance: \", cosine([doc1word1, doc1word2], [doc2word1, doc2word2]), \"\\n\", \n",
    "          \"Cosine similarity: \", 1 - cosine([doc1word1, doc1word2], [doc2word1, doc2word2]))\n",
    "\n",
    "interactive_plot = interactive(f, \n",
    "                               doc1word1=widgets.FloatSlider(value=bound/2, min = 0, max = bound),\n",
    "                               doc1word2=widgets.FloatSlider(value=bound/2, min = 0, max = bound),\n",
    "                               doc2word1=widgets.FloatSlider(value=bound/2, min = 0, max = bound),\n",
    "                               doc2word2=widgets.FloatSlider(value=bound/2, min = 0, max = bound)\n",
    "                              )\n",
    "# output = interactive_plot.children[-1]\n",
    "# output.layout.height = '350px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should've noticed an important feature of the cosine similarity; no matter what the lengths of the vectors are, the angle still tells us how close these two vectors look. This is really useful because it means that, to use cosine distance, we can have normalized or unnormalized data- it doesn't matter! Ie, we can directly compare short and long bodies of  text. In other cases, it might look quite different just because one has many more words than the other so will look different by some metrics (like the Euclidean distance discussed below); but cosine distance doesn't have that issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a direct demonstration on htis dataset: \n",
    "We expect the distance to be high between clusters 6 and 1, and close between documents within 6. Let's see if this reflects that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:14:06.680186Z",
     "start_time": "2018-04-02T07:14:06.664644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine distance between last doc and 15 last docs: 0.684149663592\n",
      "Average cosine distance between last doc and 15 first docs:  0.882843616171\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cosine distance between last doc and 15 last docs:\", np.mean([cosine(tfidf.iloc[-1], tfidf.iloc[-i]) for i in np.arange(1, 16)]))\n",
    "print(\"Average cosine distance between last doc and 15 first docs: \", np.mean([cosine(tfidf.iloc[-1], tfidf.iloc[i]) for i in np.arange(15)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looking at the average distance between the last doc (from cluster 6) and 15 other docs from cluster 6, the average distance is lower than the difference between that document and the documents from the other end, 15 docs from clusters 0 and 1. Makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another metric we might like to use is the Euclidian distance, which can be more natural to think about. That is, given two vectors (like the ones described above), we can compute the distance between the endpoints of those vectors as such:\n",
    "$$\n",
    "d = \\sqrt{\n",
    "(x_1 - y_1)^2 +\n",
    "(x_2 - y_2)^2 + \n",
    "\\dots + \n",
    "(x_n - y_n)^2 \n",
    "}\n",
    "$$\n",
    "You might recognize this as a generalized version of the Pythagorean theorem.\n",
    "Also note that this can be related to the above picture of vectors, because this exactly corresponds to the norm of the vector $\\boldsymbol{X} - \\boldsymbol{Y}$:\n",
    "$$\n",
    "|\\boldsymbol{X} - \\boldsymbol{Y}| = \n",
    "\\Huge\\lvert\\small\\begin{bmatrix}\n",
    "x_1 - y_1 \\\\\n",
    "x_2 - y_2 \\\\\n",
    "\\vdots\\\\\n",
    "x_n - y_n\n",
    "\\end{bmatrix}\\Huge\\rvert\n",
    "\\normalsize= \\sqrt{\n",
    "(x_1 - y_1)^2 +\n",
    "(x_2 - y_2)^2 + \n",
    "\\dots + \n",
    "(x_n - y_n)^2 \n",
    "}\n",
    "$$\n",
    "Using this definition, we can easily define a function to calculate a Euclidian distance. \n",
    "\n",
    "However, one caveat is that distance can be largely affected by lengths of vectors; it is apparent that vectors of distinctly different lengths will be determined to be far apart, even in the body of their text is very similar (eg, compare ['Hello World'] vs ['Hello World Hello World Hello World Hello World Hello World']). To correct for this, we can normalize the vectors (ie, divide the vector by its length, which is equivalent to dividing every single element by the vector's length/norm). All normalized vectors then have length 1. After performing this operation, the Euclidian distance can then be calculated for a more accurate idea of the distance between vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:14:09.668679Z",
     "start_time": "2018-04-02T07:14:09.664168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.7638860323\n",
      "33.7638860323\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import norm\n",
    "print(euclidean(test1, test2))\n",
    "print(euclidean(test1, test3))\n",
    "print(euclidean(test4, test5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these values are too large to make sense; the furthest distance two points can be from one another on a unit sphere is 2. Normalizing will help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T07:14:10.660446Z",
     "start_time": "2018-04-02T07:14:10.653931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2412670766236366e-16\n",
      "1.9999999999999998\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "print(euclidean(test1/norm(test1), test2/norm(test2)))\n",
    "print(euclidean(test1/norm(test1), test3/norm(test3)))\n",
    "print(euclidean(test4/norm(test4), test5/norm(test5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidian distance can actually be safely used with tfidf matrices, as they are normalized by the idf weighting. However, it becomes more important if you are using the original term matrix with raw counts of words; the distances between documents would lbe affected by the length of documents and raw frequency of words, which is not ideal. In those cases, you would want to normalize values by dividing by length of document; ie, make it so that all documents lie on the same surface of a unit hypersphere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N- grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N grams are a way of representing groups of words as a single token. This can be useful as groups of words can sometimes be more informative than just single words themselves. For example, if you looked at the words \"give\" and \"up\" between documents, they might not tell you too much. But look at the pair of words \"give up\", and then you might get some greater insight. N grams are a useful tool for this reason; clusters of words can give deeper insight by considering them as a whole, rather than just by their individual parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:03:50.416025Z",
     "start_time": "2018-04-02T08:03:50.399506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>extent</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>id_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>line_no</th>\n",
       "      <th>line_ref</th>\n",
       "      <th>pos</th>\n",
       "      <th>status</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubsaŋ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dub-saŋ-ta</td>\n",
       "      <td>first</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{d}en-ki</td>\n",
       "      <td>1</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unu₂</td>\n",
       "      <td>dwelling</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gal</td>\n",
       "      <td>big</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im-ed₃</td>\n",
       "      <td>ascend</td>\n",
       "      <td>c.0.1.1</td>\n",
       "      <td>sux</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V/i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ur III catalogue from Nibru (N1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cf extent        form        gw  id_text lang line_no  line_ref  pos  \\\n",
       "0  dubsaŋ    NaN  dub-saŋ-ta     first  c.0.1.1  sux       1       1.0   AJ   \n",
       "1    Enki    NaN    {d}en-ki         1  c.0.1.1  sux       2       2.0   DN   \n",
       "2     unu    NaN        unu₂  dwelling  c.0.1.1  sux       2       2.0    N   \n",
       "3     gal    NaN         gal       big  c.0.1.1  sux       2       2.0  V/i   \n",
       "4      ed    NaN      im-ed₃    ascend  c.0.1.1  sux       2       2.0  V/i   \n",
       "\n",
       "  status                         text_name version  \n",
       "0    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "1    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "2    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "3    NaN  Ur III catalogue from Nibru (N1)     NaN  \n",
       "4    NaN  Ur III catalogue from Nibru (N1)     NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefilter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group together by document, as before, this time without any filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:03:51.192117Z",
     "start_time": "2018-04-02T08:03:50.879257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>form</th>\n",
       "      <th>gw</th>\n",
       "      <th>lang</th>\n",
       "      <th>pos</th>\n",
       "      <th>text_name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEW</th>\n",
       "      <td>nin nun il dirig Inanak uŋ šar šeŋ ulu zipaŋ n...</td>\n",
       "      <td>nin nun il₂ dirig-ga {d}inana uŋ₃ šar₂-ra šeŋ₃...</td>\n",
       "      <td>lady prince raise exceed 1 people 3600 rain wi...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>N N V/t V/i DN N NU V/i N N N V/t V/t N QP V/t...</td>\n",
       "      <td>iddindaganAB iddindaganAB iddindaganAB iddinda...</td>\n",
       "      <td>nin[lady]N nun[prince]N il[raise]V/t dirig[exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.1</th>\n",
       "      <td>dubsaŋ Enki unu ed anzag anŋi zu ama tu zu gi ...</td>\n",
       "      <td>dub-saŋ-ta {d}en-ki unu₂ im-ed₃ an-zag-še₃ an-...</td>\n",
       "      <td>first 1 dwelling ascend horizon eclipse know m...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>AJ DN N V/i N N V/t N N V/t N V/t N N N V/i N ...</td>\n",
       "      <td>Ur III catalogue from Nibru (N1) Ur III catalo...</td>\n",
       "      <td>dubsaŋ[first]AJ Enki[1]DN unu[dwelling]N ed[as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.2</th>\n",
       "      <td>diŋir šembizida dar kur mete gud banda šerzid ...</td>\n",
       "      <td>diŋir šembi₂-zid-da dar-a nu-kur₂ me-te-bi gud...</td>\n",
       "      <td>deity kohl split different appropriate-thing o...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>N N V/t V/i N N V/i N N V/i N N N V/i N N NU V...</td>\n",
       "      <td>Ur III catalogue at Yale (Y1) Ur III catalogue...</td>\n",
       "      <td>diŋir[deity]N šembizida[kohl]N dar[split]V/t k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.01</th>\n",
       "      <td>mi niŋdu nin me šar sud nam nun re innin me hu...</td>\n",
       "      <td>mi₂ niŋ₂-du₇-e nin me šar₂-ra su₃-ra₂-še₃ nam₂...</td>\n",
       "      <td>cvne appropriate-thing lady Being 3600 distant...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>N N N N NU V/i N N DP N N V/i N V/i V/i V/i N ...</td>\n",
       "      <td>OB catalogue from Nibru (N2) OB catalogue from...</td>\n",
       "      <td>mi[cvne]N niŋdu[appropriate-thing]N nin[lady]N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.02</th>\n",
       "      <td>sud nam nun re innin me huš ud huš til hursaŋ ...</td>\n",
       "      <td>su₃-ra₂-še₃ nam₂ nun-e re-a in-nin me huš-a ud...</td>\n",
       "      <td>distant lord prince that lady Being reddish st...</td>\n",
       "      <td>sux sux sux sux sux sux sux sux sux sux sux su...</td>\n",
       "      <td>V/i N N DP N N V/i N V/i V/i N N V/i N N DP DP...</td>\n",
       "      <td>OB catalogue in the Louvre (L) OB catalogue in...</td>\n",
       "      <td>sud[distant]V/i nam[lord]N nun[prince]N re[tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         cf  \\\n",
       "id_text                                                       \n",
       "NEW       nin nun il dirig Inanak uŋ šar šeŋ ulu zipaŋ n...   \n",
       "c.0.1.1   dubsaŋ Enki unu ed anzag anŋi zu ama tu zu gi ...   \n",
       "c.0.1.2   diŋir šembizida dar kur mete gud banda šerzid ...   \n",
       "c.0.2.01  mi niŋdu nin me šar sud nam nun re innin me hu...   \n",
       "c.0.2.02  sud nam nun re innin me huš ud huš til hursaŋ ...   \n",
       "\n",
       "                                                       form  \\\n",
       "id_text                                                       \n",
       "NEW       nin nun il₂ dirig-ga {d}inana uŋ₃ šar₂-ra šeŋ₃...   \n",
       "c.0.1.1   dub-saŋ-ta {d}en-ki unu₂ im-ed₃ an-zag-še₃ an-...   \n",
       "c.0.1.2   diŋir šembi₂-zid-da dar-a nu-kur₂ me-te-bi gud...   \n",
       "c.0.2.01  mi₂ niŋ₂-du₇-e nin me šar₂-ra su₃-ra₂-še₃ nam₂...   \n",
       "c.0.2.02  su₃-ra₂-še₃ nam₂ nun-e re-a in-nin me huš-a ud...   \n",
       "\n",
       "                                                         gw  \\\n",
       "id_text                                                       \n",
       "NEW       lady prince raise exceed 1 people 3600 rain wi...   \n",
       "c.0.1.1   first 1 dwelling ascend horizon eclipse know m...   \n",
       "c.0.1.2   deity kohl split different appropriate-thing o...   \n",
       "c.0.2.01  cvne appropriate-thing lady Being 3600 distant...   \n",
       "c.0.2.02  distant lord prince that lady Being reddish st...   \n",
       "\n",
       "                                                       lang  \\\n",
       "id_text                                                       \n",
       "NEW       sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.1.1   sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.1.2   sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.2.01  sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "c.0.2.02  sux sux sux sux sux sux sux sux sux sux sux su...   \n",
       "\n",
       "                                                        pos  \\\n",
       "id_text                                                       \n",
       "NEW       N N V/t V/i DN N NU V/i N N N V/t V/t N QP V/t...   \n",
       "c.0.1.1   AJ DN N V/i N N V/t N N V/t N V/t N N N V/i N ...   \n",
       "c.0.1.2   N N V/t V/i N N V/i N N V/i N N N V/i N N NU V...   \n",
       "c.0.2.01  N N N N NU V/i N N DP N N V/i N V/i V/i V/i N ...   \n",
       "c.0.2.02  V/i N N DP N N V/i N V/i V/i N N V/i N N DP DP...   \n",
       "\n",
       "                                                  text_name  \\\n",
       "id_text                                                       \n",
       "NEW       iddindaganAB iddindaganAB iddindaganAB iddinda...   \n",
       "c.0.1.1   Ur III catalogue from Nibru (N1) Ur III catalo...   \n",
       "c.0.1.2   Ur III catalogue at Yale (Y1) Ur III catalogue...   \n",
       "c.0.2.01  OB catalogue from Nibru (N2) OB catalogue from...   \n",
       "c.0.2.02  OB catalogue in the Louvre (L) OB catalogue in...   \n",
       "\n",
       "                                                       Term  \n",
       "id_text                                                      \n",
       "NEW       nin[lady]N nun[prince]N il[raise]V/t dirig[exc...  \n",
       "c.0.1.1   dubsaŋ[first]AJ Enki[1]DN unu[dwelling]N ed[as...  \n",
       "c.0.1.2   diŋir[deity]N šembizida[kohl]N dar[split]V/t k...  \n",
       "c.0.2.01  mi[cvne]N niŋdu[appropriate-thing]N nin[lady]N...  \n",
       "c.0.2.02  sud[distant]V/i nam[lord]N nun[prince]N re[tha...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped2 = alltex.groupby(\"id_text\").aggregate(\" \".join) #this line of code lumps together all documents' terms together, and joins them as a single space separated string\n",
    "grouped2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a count vectorizer as before, but this time, we define an ngram range to produce ngrams of n = 1, 2, and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:09:30.659161Z",
     "start_time": "2018-04-02T08:09:30.650635Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(token_pattern='[^ ]+', lowercase = False, ngram_range=(1, 3), max_df = .95, min_df = .05) #initialize a count vectorizer object with correct tokenization for this term format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:09:32.710324Z",
     "start_time": "2018-04-02T08:09:31.651829Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/2[1/2]NU</th>\n",
       "      <th>10[10]NU</th>\n",
       "      <th>1[1]NU</th>\n",
       "      <th>2-kam-ma[2nd]NU</th>\n",
       "      <th>2[2]NU</th>\n",
       "      <th>3-kam-ma[3rd]NU</th>\n",
       "      <th>3[3]NU</th>\n",
       "      <th>4-kam-ma[4th]NU</th>\n",
       "      <th>4[4]NU</th>\n",
       "      <th>5-kam-ma[5th]NU</th>\n",
       "      <th>...</th>\n",
       "      <th>šud[prayer]N</th>\n",
       "      <th>šudul[yoke]N</th>\n",
       "      <th>šukur[ration]N</th>\n",
       "      <th>šul[youth]V/i</th>\n",
       "      <th>šul[youth]V/i Suen[1]DN</th>\n",
       "      <th>šul[youth]V/i Utu[1]DN</th>\n",
       "      <th>šuluh[cleansing]N</th>\n",
       "      <th>šum[give]V/t</th>\n",
       "      <th>šusi[finger]N</th>\n",
       "      <th>šuš[cover]V/t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEW</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1/2[1/2]NU  10[10]NU  1[1]NU  2-kam-ma[2nd]NU  2[2]NU  \\\n",
       "id_text                                                           \n",
       "NEW                0         0       0                0       0   \n",
       "c.0.1.1            0         0       0                0       0   \n",
       "c.0.1.2            0         1       0                0       0   \n",
       "c.0.2.01           0         0       0                0       0   \n",
       "c.0.2.02           0         0       0                0       1   \n",
       "\n",
       "          3-kam-ma[3rd]NU  3[3]NU  4-kam-ma[4th]NU  4[4]NU  5-kam-ma[5th]NU  \\\n",
       "id_text                                                                       \n",
       "NEW                     0       0                0       0                0   \n",
       "c.0.1.1                 0       0                0       0                0   \n",
       "c.0.1.2                 0       0                0       0                0   \n",
       "c.0.2.01                0       0                0       0                0   \n",
       "c.0.2.02                0       0                0       0                0   \n",
       "\n",
       "              ...        šud[prayer]N  šudul[yoke]N  šukur[ration]N  \\\n",
       "id_text       ...                                                     \n",
       "NEW           ...                   0             1               0   \n",
       "c.0.1.1       ...                   0             0               0   \n",
       "c.0.1.2       ...                   0             0               0   \n",
       "c.0.2.01      ...                   0             0               0   \n",
       "c.0.2.02      ...                   0             0               0   \n",
       "\n",
       "          šul[youth]V/i  šul[youth]V/i Suen[1]DN  šul[youth]V/i Utu[1]DN  \\\n",
       "id_text                                                                    \n",
       "NEW                   0                        0                       0   \n",
       "c.0.1.1               1                        0                       0   \n",
       "c.0.1.2               1                        0                       0   \n",
       "c.0.2.01              1                        0                       0   \n",
       "c.0.2.02              3                        0                       0   \n",
       "\n",
       "          šuluh[cleansing]N  šum[give]V/t  šusi[finger]N  šuš[cover]V/t  \n",
       "id_text                                                                  \n",
       "NEW                       0             4              0              0  \n",
       "c.0.1.1                   0             0              0              0  \n",
       "c.0.1.2                   0             0              0              0  \n",
       "c.0.2.01                  0             0              0              0  \n",
       "c.0.2.02                  0             0              0              0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2 = cv2.fit_transform(list(grouped2.Term))\n",
    "dtm2df = pd.DataFrame(dtm2.toarray(), columns=cv2.get_feature_names(), index=grouped2.index)\n",
    "dtm2df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:11:49.470817Z",
     "start_time": "2018-04-02T08:11:49.464803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a[arm]N namursaŋ[heroism]N', 'barag[sanctum]N mah[great]V/i',\n",
       "       'dumu[child]N aŋ[measure]V/t', 'gabari[copy]N tuku[acquire]V/t',\n",
       "       'hili[attractiveness]N gur[lift]V/t', 'kaš[decision]N bar[outside]V/t',\n",
       "       'munus[woman]N zid[right]V/i', 'murmara[noise]N ša[cvve]V/t',\n",
       "       'nadeg[advice]N deg[collect]V/t', 'nam[fate]N dug[good]V/i tar[cut]V/t',\n",
       "       'namtil[life]N sud[distant]V/i', 'ni[fear]N melim[splendor]N',\n",
       "       'ni[fear]N teŋ[approach]V/i', 'ni[self]RP ten[extinguish]V/t',\n",
       "       'niŋziŋal[living-creature]N', 'saŋki[forehead]N gid[long]V/i',\n",
       "       'sig[weak]V/i iginim[land]N', 'sipad[shepherd]N zid[right]V/i',\n",
       "       'suhuš[foundation]N gin[firm]V/i', 'ud[storm]N huš[reddish]V/i',\n",
       "       'uru[subscript]N adab[drum]N', 'uŋ[people]N daŋal[wide]V/i',\n",
       "       'uŋ[people]N giggi[black]V/i', 'uŋ[people]N lu[abundant]V/i',\n",
       "       'zid[right]V/i bar[outside]V/t', 'ŋal[open]V/t taka[abandon]V/t',\n",
       "       'ŋala[cvne]N dag[demolish]V/t', 'ŋeš[tree]N tuku[acquire]V/t',\n",
       "       'ŋeštug[ear]N daŋal[wide]V/i', 'ŋi[night]N ŋiʾunak[night]N',\n",
       "       'šeg₁1[loud-noise]N gi[turn]V/i', 'šim[aromatics]N eren[cedar]N'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2df.columns[dtm2df.columns.str.len() > 25] # a somewhat contrived way to make sure we have some longer grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that we indeed have generated 1, 2, and 3 grams! The column headings have just put the second term on a separate line from the first term in 2 grams. We can now potentially do some nice things with this, but first we have to check for the stuff that we filtered out in the first half; bigrams with those won't be terribly useful, as they aren't real information (things like NA, (X)).\n",
    "\n",
    "\n",
    "So we generate a list of columns where we have these nonsense words, and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:11:57.771100Z",
     "start_time": "2018-04-02T08:11:57.738503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/2[1/2]NU</th>\n",
       "      <th>10[10]NU</th>\n",
       "      <th>1[1]NU</th>\n",
       "      <th>2-kam-ma[2nd]NU</th>\n",
       "      <th>2[2]NU</th>\n",
       "      <th>3-kam-ma[3rd]NU</th>\n",
       "      <th>3[3]NU</th>\n",
       "      <th>4-kam-ma[4th]NU</th>\n",
       "      <th>4[4]NU</th>\n",
       "      <th>5-kam-ma[5th]NU</th>\n",
       "      <th>...</th>\n",
       "      <th>šud[prayer]N</th>\n",
       "      <th>šudul[yoke]N</th>\n",
       "      <th>šukur[ration]N</th>\n",
       "      <th>šul[youth]V/i</th>\n",
       "      <th>šul[youth]V/i Suen[1]DN</th>\n",
       "      <th>šul[youth]V/i Utu[1]DN</th>\n",
       "      <th>šuluh[cleansing]N</th>\n",
       "      <th>šum[give]V/t</th>\n",
       "      <th>šusi[finger]N</th>\n",
       "      <th>šuš[cover]V/t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEW</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.1.2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.04</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.0.2.08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.1.23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.1.24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.1.25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.1.26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.1.27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.1.28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.2.1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.2.2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.2.3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c.6.2.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1/2[1/2]NU  10[10]NU  1[1]NU  2-kam-ma[2nd]NU  2[2]NU  \\\n",
       "id_text                                                           \n",
       "NEW                0         0       0                0       0   \n",
       "c.0.1.1            0         0       0                0       0   \n",
       "c.0.1.2            0         1       0                0       0   \n",
       "c.0.2.01           0         0       0                0       0   \n",
       "c.0.2.02           0         0       0                0       1   \n",
       "c.0.2.03           0         0       0                0       0   \n",
       "c.0.2.04           0         0       0                0       0   \n",
       "c.0.2.06           0         0       0                0       0   \n",
       "c.0.2.07           0         0       5                0       0   \n",
       "c.0.2.08           0         0       0                0       0   \n",
       "...              ...       ...     ...              ...     ...   \n",
       "c.6.1.23           0         0       0                0       1   \n",
       "c.6.1.24           0         0       0                0       0   \n",
       "c.6.1.25           0         0       2                0       0   \n",
       "c.6.1.26           1         0       0                0       1   \n",
       "c.6.1.27           1         0       0                0       0   \n",
       "c.6.1.28           0         0       0                0       0   \n",
       "c.6.2.1            1         0       2                0       0   \n",
       "c.6.2.2            0         0       0                0       0   \n",
       "c.6.2.3            0         0       2                0       1   \n",
       "c.6.2.5            0         0       0                0       0   \n",
       "\n",
       "          3-kam-ma[3rd]NU  3[3]NU  4-kam-ma[4th]NU  4[4]NU  5-kam-ma[5th]NU  \\\n",
       "id_text                                                                       \n",
       "NEW                     0       0                0       0                0   \n",
       "c.0.1.1                 0       0                0       0                0   \n",
       "c.0.1.2                 0       0                0       0                0   \n",
       "c.0.2.01                0       0                0       0                0   \n",
       "c.0.2.02                0       0                0       0                0   \n",
       "c.0.2.03                0       0                0       0                0   \n",
       "c.0.2.04                0       1                0       0                0   \n",
       "c.0.2.06                0       0                0       0                0   \n",
       "c.0.2.07                0       2                0       0                0   \n",
       "c.0.2.08                0       0                0       0                0   \n",
       "...                   ...     ...              ...     ...              ...   \n",
       "c.6.1.23                0       0                0       0                0   \n",
       "c.6.1.24                0       0                0       0                0   \n",
       "c.6.1.25                0       0                0       0                0   \n",
       "c.6.1.26                0       0                0       0                0   \n",
       "c.6.1.27                0       0                0       0                0   \n",
       "c.6.1.28                0       0                0       0                0   \n",
       "c.6.2.1                 0       0                0       0                0   \n",
       "c.6.2.2                 0       0                0       0                0   \n",
       "c.6.2.3                 0       1                0       0                0   \n",
       "c.6.2.5                 0       0                0       0                0   \n",
       "\n",
       "              ...        šud[prayer]N  šudul[yoke]N  šukur[ration]N  \\\n",
       "id_text       ...                                                     \n",
       "NEW           ...                   0             1               0   \n",
       "c.0.1.1       ...                   0             0               0   \n",
       "c.0.1.2       ...                   0             0               0   \n",
       "c.0.2.01      ...                   0             0               0   \n",
       "c.0.2.02      ...                   0             0               0   \n",
       "c.0.2.03      ...                   0             0               0   \n",
       "c.0.2.04      ...                   0             0               0   \n",
       "c.0.2.06      ...                   0             0               0   \n",
       "c.0.2.07      ...                   0             0               0   \n",
       "c.0.2.08      ...                   0             0               0   \n",
       "...           ...                 ...           ...             ...   \n",
       "c.6.1.23      ...                   0             0               0   \n",
       "c.6.1.24      ...                   0             0               0   \n",
       "c.6.1.25      ...                   0             0               0   \n",
       "c.6.1.26      ...                   0             0               0   \n",
       "c.6.1.27      ...                   0             0               0   \n",
       "c.6.1.28      ...                   0             0               0   \n",
       "c.6.2.1       ...                   0             1               1   \n",
       "c.6.2.2       ...                   0             0               0   \n",
       "c.6.2.3       ...                   0             0               0   \n",
       "c.6.2.5       ...                   0             0               0   \n",
       "\n",
       "          šul[youth]V/i  šul[youth]V/i Suen[1]DN  šul[youth]V/i Utu[1]DN  \\\n",
       "id_text                                                                    \n",
       "NEW                   0                        0                       0   \n",
       "c.0.1.1               1                        0                       0   \n",
       "c.0.1.2               1                        0                       0   \n",
       "c.0.2.01              1                        0                       0   \n",
       "c.0.2.02              3                        0                       0   \n",
       "c.0.2.03              0                        0                       0   \n",
       "c.0.2.04              1                        0                       0   \n",
       "c.0.2.06              0                        0                       0   \n",
       "c.0.2.07              0                        0                       0   \n",
       "c.0.2.08              1                        0                       0   \n",
       "...                 ...                      ...                     ...   \n",
       "c.6.1.23              1                        0                       0   \n",
       "c.6.1.24              0                        0                       0   \n",
       "c.6.1.25              0                        0                       0   \n",
       "c.6.1.26              0                        0                       0   \n",
       "c.6.1.27              0                        0                       0   \n",
       "c.6.1.28              0                        0                       0   \n",
       "c.6.2.1               0                        0                       0   \n",
       "c.6.2.2               0                        0                       0   \n",
       "c.6.2.3               2                        0                       0   \n",
       "c.6.2.5               0                        0                       0   \n",
       "\n",
       "          šuluh[cleansing]N  šum[give]V/t  šusi[finger]N  šuš[cover]V/t  \n",
       "id_text                                                                  \n",
       "NEW                       0             4              0              0  \n",
       "c.0.1.1                   0             0              0              0  \n",
       "c.0.1.2                   0             0              0              0  \n",
       "c.0.2.01                  0             0              0              0  \n",
       "c.0.2.02                  0             0              0              0  \n",
       "c.0.2.03                  0             0              0              0  \n",
       "c.0.2.04                  0             0              0              0  \n",
       "c.0.2.06                  0             0              0              0  \n",
       "c.0.2.07                  0             0              0              0  \n",
       "c.0.2.08                  0             0              0              0  \n",
       "...                     ...           ...            ...            ...  \n",
       "c.6.1.23                  0             2              0              0  \n",
       "c.6.1.24                  0             0              0              1  \n",
       "c.6.1.25                  0             1              0              1  \n",
       "c.6.1.26                  0             3              0              0  \n",
       "c.6.1.27                  0             0              0              0  \n",
       "c.6.1.28                  0             1              0              0  \n",
       "c.6.2.1                   0             0              1              2  \n",
       "c.6.2.2                   0             0              0              0  \n",
       "c.6.2.3                   0             9              3              1  \n",
       "c.6.2.5                   0             1              0              2  \n",
       "\n",
       "[357 rows x 771 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonsense = [\"[nan]nan\" in i or \"[X](X)\" in i for i in cv2.get_feature_names()]\n",
    "dtm2df = dtm2df.drop(np.arange(len(nonsense))[nonsense])\n",
    "dtm2df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output this dtm for use in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T08:12:29.320060Z",
     "start_time": "2018-04-02T08:12:29.141055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm2df.to_csv(\"cleanngrams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 1 <a id='subsection 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro to subsection 1 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Notes for Notebook Style:\n",
    "\n",
    "- Follow [PEP 8](https://www.python.org/dev/peps/pep-0008/) style guide for Python\n",
    "- No two cells of successive code or Markdown\n",
    "- Run all cells with no errors\n",
    "- Clear all cell output before pushing\n",
    "- Create a binder for the repo on [mybinder.org](http://mybinder.org) and paste the badge to the top of the README markdown file\n",
    "\n",
    "\n",
    "#### Notes for Code Style:\n",
    "- Each line or section of code should be accompanied with a comment\n",
    "- Comments and code lines should not be too long\n",
    "- Naming variables: use descriptive names (titanic vs. data), use underscores, not camel case\n",
    "\n",
    "#### Notes for Visualizations\n",
    "- Graphs should be displayed with titles and label axes\n",
    "\n",
    "#### Example of good code and graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: X, X, X\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "245px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "334px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
